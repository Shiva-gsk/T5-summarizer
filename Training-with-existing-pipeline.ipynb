{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shiva\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Loading pipeline with T5 model\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[2000:2100]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset_train, dataset_test = train_test_split(df, test_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\shiva\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--rouge\\b01e0accf3bd6dd24839b769a5fda24e14995071570870922c71970b3a6ed886 (last modified on Sat Dec 14 15:57:24 2024) since it couldn't be found locally at evaluate-metric--rouge, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2001</td>\n",
       "      <td>B001E5E29A</td>\n",
       "      <td>A1CPC3HEDIT8B5</td>\n",
       "      <td>P. L. Carter \"historyteacher\"</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1178496000</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>I usually make pancakes from scratch and have ...</td>\n",
       "      <td>summarize: i usually make pancakes from scratc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2002</td>\n",
       "      <td>B001E5E29A</td>\n",
       "      <td>A81HMEGGVESJP</td>\n",
       "      <td>Mrs. G \"B. Real\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1207440000</td>\n",
       "      <td>Great tasting pancake  mix</td>\n",
       "      <td>This is the best tasting pancake mix in the ma...</td>\n",
       "      <td>summarize: this is the best tasting pancake mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2003</td>\n",
       "      <td>B001E5E29A</td>\n",
       "      <td>A13CUVB0LKBTB0</td>\n",
       "      <td>Patricia A. Lukens \"Unifier\"</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1246838400</td>\n",
       "      <td>Stonewall Pancake Mix</td>\n",
       "      <td>My family absolutely loves this pancake and wa...</td>\n",
       "      <td>summarize: my family absolutely loves this pan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2004</td>\n",
       "      <td>B001E5E29A</td>\n",
       "      <td>A2Q8RE77HMDIK7</td>\n",
       "      <td>J. Remsen</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1326585600</td>\n",
       "      <td>Delicious waffles!</td>\n",
       "      <td>We use the Farmhouse Pancake and Waffle Mix to...</td>\n",
       "      <td>summarize: we use the farmhouse pancake and wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2005</td>\n",
       "      <td>B001E5E29A</td>\n",
       "      <td>A3VKPPHX72R4QI</td>\n",
       "      <td>P. Mullen \"mullnc\"</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1215561600</td>\n",
       "      <td>Great taste and great price! A+++</td>\n",
       "      <td>I love Belgian waffles and this mix makes a de...</td>\n",
       "      <td>summarize: i love belgian waffles and this mix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>2096</td>\n",
       "      <td>B007POA176</td>\n",
       "      <td>A22NBJNDK5JYWJ</td>\n",
       "      <td>raybabe</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1343174400</td>\n",
       "      <td>They should say just add milk....</td>\n",
       "      <td>i got a bag of these and the veggie sticks. ha...</td>\n",
       "      <td>summarize: i got a bag of these and the veggie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>2097</td>\n",
       "      <td>B007POA176</td>\n",
       "      <td>AFZW48UFK3G0H</td>\n",
       "      <td>C. Hancock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1347321600</td>\n",
       "      <td>Delicious</td>\n",
       "      <td>This was a new product to me.  They were very ...</td>\n",
       "      <td>summarize: this was a new product to me. they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>2098</td>\n",
       "      <td>B007POA176</td>\n",
       "      <td>A830NL2LWO3TV</td>\n",
       "      <td>S. Napolitano \"holistic health coach\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338854400</td>\n",
       "      <td>Great new GMO-free snack!</td>\n",
       "      <td>I was very pleased to stumble upon this brand,...</td>\n",
       "      <td>summarize: i was very pleased to stumble upon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>2099</td>\n",
       "      <td>B0001OINNQ</td>\n",
       "      <td>A2HJM83SBQXZJB</td>\n",
       "      <td>Diane \"Madison Book lover\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1325980800</td>\n",
       "      <td>Perfect Gift</td>\n",
       "      <td>This product was a gift to a far distant relat...</td>\n",
       "      <td>summarize: this product was a gift to a far di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>2100</td>\n",
       "      <td>B000EPP56U</td>\n",
       "      <td>A1G6Q2NQMJ2C3X</td>\n",
       "      <td>ARealAVFan</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1149897600</td>\n",
       "      <td>Excellent rice crackers</td>\n",
       "      <td>I always disliked soggy or soft crackers with ...</td>\n",
       "      <td>summarize: i always disliked soggy or soft cra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId                            ProfileName  \\\n",
       "2000  2001  B001E5E29A  A1CPC3HEDIT8B5          P. L. Carter \"historyteacher\"   \n",
       "2001  2002  B001E5E29A   A81HMEGGVESJP                       Mrs. G \"B. Real\"   \n",
       "2002  2003  B001E5E29A  A13CUVB0LKBTB0           Patricia A. Lukens \"Unifier\"   \n",
       "2003  2004  B001E5E29A  A2Q8RE77HMDIK7                              J. Remsen   \n",
       "2004  2005  B001E5E29A  A3VKPPHX72R4QI                     P. Mullen \"mullnc\"   \n",
       "...    ...         ...             ...                                    ...   \n",
       "2095  2096  B007POA176  A22NBJNDK5JYWJ                                raybabe   \n",
       "2096  2097  B007POA176   AFZW48UFK3G0H                             C. Hancock   \n",
       "2097  2098  B007POA176   A830NL2LWO3TV  S. Napolitano \"holistic health coach\"   \n",
       "2098  2099  B0001OINNQ  A2HJM83SBQXZJB             Diane \"Madison Book lover\"   \n",
       "2099  2100  B000EPP56U  A1G6Q2NQMJ2C3X                             ARealAVFan   \n",
       "\n",
       "      HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "2000                    11                      14      5  1178496000   \n",
       "2001                     3                       3      4  1207440000   \n",
       "2002                     5                       6      5  1246838400   \n",
       "2003                     2                       2      5  1326585600   \n",
       "2004                     4                       5      5  1215561600   \n",
       "...                    ...                     ...    ...         ...   \n",
       "2095                     1                       1      3  1343174400   \n",
       "2096                     0                       0      5  1347321600   \n",
       "2097                     0                       0      5  1338854400   \n",
       "2098                     0                       0      5  1325980800   \n",
       "2099                     8                       8      5  1149897600   \n",
       "\n",
       "                                Summary  \\\n",
       "2000                            Awesome   \n",
       "2001         Great tasting pancake  mix   \n",
       "2002              Stonewall Pancake Mix   \n",
       "2003                 Delicious waffles!   \n",
       "2004  Great taste and great price! A+++   \n",
       "...                                 ...   \n",
       "2095  They should say just add milk....   \n",
       "2096                          Delicious   \n",
       "2097          Great new GMO-free snack!   \n",
       "2098                       Perfect Gift   \n",
       "2099            Excellent rice crackers   \n",
       "\n",
       "                                                   Text  \\\n",
       "2000  I usually make pancakes from scratch and have ...   \n",
       "2001  This is the best tasting pancake mix in the ma...   \n",
       "2002  My family absolutely loves this pancake and wa...   \n",
       "2003  We use the Farmhouse Pancake and Waffle Mix to...   \n",
       "2004  I love Belgian waffles and this mix makes a de...   \n",
       "...                                                 ...   \n",
       "2095  i got a bag of these and the veggie sticks. ha...   \n",
       "2096  This was a new product to me.  They were very ...   \n",
       "2097  I was very pleased to stumble upon this brand,...   \n",
       "2098  This product was a gift to a far distant relat...   \n",
       "2099  I always disliked soggy or soft crackers with ...   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "2000  summarize: i usually make pancakes from scratc...  \n",
       "2001  summarize: this is the best tasting pancake mi...  \n",
       "2002  summarize: my family absolutely loves this pan...  \n",
       "2003  summarize: we use the farmhouse pancake and wa...  \n",
       "2004  summarize: i love belgian waffles and this mix...  \n",
       "...                                                 ...  \n",
       "2095  summarize: i got a bag of these and the veggie...  \n",
       "2096  summarize: this was a new product to me. they ...  \n",
       "2097  summarize: i was very pleased to stumble upon ...  \n",
       "2098  summarize: this product was a gift to a far di...  \n",
       "2099  summarize: i always disliked soggy or soft cra...  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    return summarizer(text, max_length=12, min_length=2, do_sample=False)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_24848\\1296683256.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['summary'] = data['preprocessed_text'].apply(summarize)\n"
     ]
    }
   ],
   "source": [
    "data['summary'] = data['preprocessed_text'].apply(summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1: 0.0983\n",
      "rouge2: 0.0194\n",
      "rougeL: 0.0932\n",
      "rougeLsum: 0.0938\n"
     ]
    }
   ],
   "source": [
    "results = rouge.compute(\n",
    "    predictions=data[\"summary\"].tolist(),\n",
    "    references=data[\"Summary\"].tolist()\n",
    ")\n",
    "for metric, score in results.items():\n",
    "    print(f\"{metric}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pprint\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"./Finetuned_T5/tokenizer\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"./Finetuned_T5/model-2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>summarize: i have bought several of the vitali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>summarize: product arrived labeled as jumbo sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>summarize: this is a confection that has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>summarize: if you are looking for the secret i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>summarize: great taffy at a great price. there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A3A63RACXR1XIL</td>\n",
       "      <td>A. Boodhoo \"deaddodo\"</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1204502400</td>\n",
       "      <td>constipation</td>\n",
       "      <td>we switched from the advance similac to the or...</td>\n",
       "      <td>summarize: we switched from the advance simila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A5VVRGL8JA7R</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1306368000</td>\n",
       "      <td>Constipation Not A Problem if...</td>\n",
       "      <td>Like the bad reviews say, the organic formula ...</td>\n",
       "      <td>summarize: like the bad reviews say, the organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A2TGDTJ8YCU6PD</td>\n",
       "      <td>geena77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1347494400</td>\n",
       "      <td>Love this formula!</td>\n",
       "      <td>I wanted to solely breastfeed but was unable t...</td>\n",
       "      <td>summarize: i wanted to solely breastfeed but w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>AUV4GIZZE693O</td>\n",
       "      <td>Susan Coe \"sueysis\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1203638400</td>\n",
       "      <td>very convenient</td>\n",
       "      <td>i love the fact that i can get this delieved t...</td>\n",
       "      <td>summarize: i love the fact that i can get this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>B000P41A28</td>\n",
       "      <td>A82WIMR4RSVLI</td>\n",
       "      <td>Emrose mom</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1337472000</td>\n",
       "      <td>The best weve tried so far</td>\n",
       "      <td>We have a 7 week old... He had gas and constip...</td>\n",
       "      <td>summarize: we have a 7 week old... he had gas ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id   ProductId          UserId                      ProfileName  \\\n",
       "0         1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1         2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2         3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3         4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4         5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...     ...         ...             ...                              ...   \n",
       "9995   9996  B000P41A28  A3A63RACXR1XIL            A. Boodhoo \"deaddodo\"   \n",
       "9996   9997  B000P41A28    A5VVRGL8JA7R                             Adam   \n",
       "9997   9998  B000P41A28  A2TGDTJ8YCU6PD                          geena77   \n",
       "9998   9999  B000P41A28   AUV4GIZZE693O              Susan Coe \"sueysis\"   \n",
       "9999  10000  B000P41A28   A82WIMR4RSVLI                       Emrose mom   \n",
       "\n",
       "      HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                        1                       1      5  1303862400   \n",
       "1                        0                       0      1  1346976000   \n",
       "2                        1                       1      4  1219017600   \n",
       "3                        3                       3      2  1307923200   \n",
       "4                        0                       0      5  1350777600   \n",
       "...                    ...                     ...    ...         ...   \n",
       "9995                    10                      15      1  1204502400   \n",
       "9996                     2                       3      5  1306368000   \n",
       "9997                     0                       0      5  1347494400   \n",
       "9998                     1                       2      5  1203638400   \n",
       "9999                     0                       1      4  1337472000   \n",
       "\n",
       "                               Summary  \\\n",
       "0                Good Quality Dog Food   \n",
       "1                    Not as Advertised   \n",
       "2                \"Delight\" says it all   \n",
       "3                       Cough Medicine   \n",
       "4                          Great taffy   \n",
       "...                                ...   \n",
       "9995                      constipation   \n",
       "9996  Constipation Not A Problem if...   \n",
       "9997                Love this formula!   \n",
       "9998                   very convenient   \n",
       "9999        The best weve tried so far   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     I have bought several of the Vitality canned d...   \n",
       "1     Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2     This is a confection that has been around a fe...   \n",
       "3     If you are looking for the secret ingredient i...   \n",
       "4     Great taffy at a great price.  There was a wid...   \n",
       "...                                                 ...   \n",
       "9995  we switched from the advance similac to the or...   \n",
       "9996  Like the bad reviews say, the organic formula ...   \n",
       "9997  I wanted to solely breastfeed but was unable t...   \n",
       "9998  i love the fact that i can get this delieved t...   \n",
       "9999  We have a 7 week old... He had gas and constip...   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "0     summarize: i have bought several of the vitali...  \n",
       "1     summarize: product arrived labeled as jumbo sa...  \n",
       "2     summarize: this is a confection that has been ...  \n",
       "3     summarize: if you are looking for the secret i...  \n",
       "4     summarize: great taffy at a great price. there...  \n",
       "...                                                 ...  \n",
       "9995  summarize: we switched from the advance simila...  \n",
       "9996  summarize: like the bad reviews say, the organ...  \n",
       "9997  summarize: i wanted to solely breastfeed but w...  \n",
       "9998  summarize: i love the fact that i can get this...  \n",
       "9999  summarize: we have a 7 week old... he had gas ...  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_24848\\4149046823.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data['summary'] = new_data['preprocessed_text'].apply(summarize)\n"
     ]
    }
   ],
   "source": [
    "new_data = df[2000:]  # Selecting data that my model don't know\n",
    "new_data['summary'] = new_data['preprocessed_text'].apply(summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1: 0.1450\n",
      "rouge2: 0.0457\n",
      "rougeL: 0.1430\n",
      "rougeLsum: 0.1428\n"
     ]
    }
   ],
   "source": [
    "results = rouge.compute(\n",
    "    predictions=new_data[\"summary\"].tolist(),\n",
    "    references=new_data[\"Summary\"].tolist()\n",
    ")\n",
    "for metric, score in results.items():\n",
    "    print(f\"{metric}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On just training on 800 examples our model got better. So we can proceeded to train on huge examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
